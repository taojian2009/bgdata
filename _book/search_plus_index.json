{"./":{"url":"./","title":"Introduction","keywords":"","body":"大数据相关知识学习笔记 Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 20:17:46 "},"docs/01.Linux高级/01.Linux基础.html":{"url":"docs/01.Linux高级/01.Linux基础.html","title":"Linux高级","keywords":"","body":"Linux Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 19:55:59 "},"docs/02.Zookeeper框架/01.Zookeeper.html":{"url":"docs/02.Zookeeper框架/01.Zookeeper.html","title":"Zookeeper框架","keywords":"","body":"Zookeeper介绍 Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 19:55:59 "},"docs/03.Hadoop技术/01.Hadoop技术介绍.html":{"url":"docs/03.Hadoop技术/01.Hadoop技术介绍.html","title":"Hadoop技术","keywords":"","body":"Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 19:54:19 "},"docs/04.HDFS分布式文件系统/0.HDFS分布式文件系统.html":{"url":"docs/04.HDFS分布式文件系统/0.HDFS分布式文件系统.html","title":"HDFS分布式文件系统","keywords":"","body":"企业存储系统 解决大规模数据存储的问题，需要存储硬件的支持 Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 13:11:08 "},"docs/04.HDFS分布式文件系统/1.企业存储系统.html":{"url":"docs/04.HDFS分布式文件系统/1.企业存储系统.html","title":"企业存储系统","keywords":"","body":"1.1 硬盘 SATA硬盘 - 机械硬盘 SATA SSD硬盘 - 固态硬盘 RAID磁盘阵列 - 扩容难 1.2 文件系统 计算机的文件系统是一种存储和组织计算机数据的方法， 文件系统使用文件和树形目录的抽象逻辑 元数据 [root@node2 ~]# ll total 32 -rw-------. 1 root root 2117 Apr 8 2020 anaconda-ks.cfg drwxr-xr-x. 2 root root 6 Aug 30 09:33 Desktop Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 20:19:37 "},"docs/04.HDFS分布式文件系统/2.分布式存储问题.html":{"url":"docs/04.HDFS分布式文件系统/2.分布式存储问题.html","title":"分布式存储问题","keywords":"","body":"1. 如何解决海量存储问题 通过横向添加主机，实现横向拓展。 2. 如何解决数据查询便捷 使用元数据， 统一管理数据 3. 如何解决大文件传输慢的问题 对文件进行切片存储，元数据 记录切片信息 4. 如何解决数据丢失问题 使用副本机制 5. 如何解决查询视角一致问题 元数据信息抽象成统一的目录树 Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 20:19:37 "},"docs/04.HDFS分布式文件系统/3.分布式文件HDFS.html":{"url":"docs/04.HDFS分布式文件系统/3.分布式文件HDFS.html","title":"分布式文件HDFS","keywords":"","body":"HDFS简介 HDFS(Hadoop Distributed File System)是apache hadoop的一个子项目。 HDFS解决的问题是数据存储。 Doug Cutting基于骨骼的GFS论文，开发了一个新的文件系统，叫HDFS。、 HDFS设计目录 能实现故障快速恢复 倾向于批量数据处理。 比较适合存储大文件 +Write-One-Read-Many 不适合的场景 低延时 存大量小文件 多方读写 HDFS架构特性 使用master/slave 架构，一个HDFS集群一般有1个namenode和多个datanode组成。 NameNode是主节点，DataNode是从节点。 HDFS主要组件 HDFS Client 负责与NameNode或者DataNode交互，读写数据 NameNode 管理命名空间 管理block映射 配置副本策略 处理客户端请求 DataNode 存储世界的数据block 执行数据的读写操作 定时向namenode汇报block信息 SecondaryNode 辅助NameNode, 分担工作量 定期合并fsimage和fsedits, 并推送给NameNode 紧急情况下恢复namenode 分块机制 默认blocksize=128MB 当切片不足128MB时候，比如只有2MB，也会占用一个block, 虽然实际存储空间只用了2MB，但是命令空间还是128MB， 某种程度上，block是一种逻辑切片。 副本机制 replication=3 提高容错机制。 NameSpace命名空间 hdfs://namenode:port/dir1/dir2/a.txt 元数据管理 NameNode管理的元数据包含两种类型： 文件自身属性，比如文件名，大小，修改时间等 文件块位置映射信息，记录文件块存在那个位置 HDFS副本放置策略 机架感知。 Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 13:34:50 "},"docs/04.HDFS分布式文件系统/4.HDFS-SHELL命令行使用.html":{"url":"docs/04.HDFS分布式文件系统/4.HDFS-SHELL命令行使用.html","title":"HDFS SHELL命令行操作","keywords":"","body":"常见的shell命令操作 ls 显示文件列表 hadoop fs -ls / lsr 递归显示文件列表 hadoop fs -lsr / mkdir -p 创建文件夹 hadoop fs -mkdir -p /aa/bb/cc put 上传文件 hadoop fs -put a.txt /aa/a.txt moveFromLocal 移动文件,本地文件会被删除 hadoop fs -moveFromLocal a /dir/a get 下载文件 hadoop fs -get /dit/a.txt a.txt getMerge 合并下载, 将dir的文件全部合并，然后下载 hadoop fs -getMerge /dir a.txt mv 移动HDFS上的目录 hadoop fs -mv /dir1 /dir2 rm 删除文件 hadoop fs -rm -r /dir cp hadoop fs -cp /dir/a.txt /dir1/a.txt cat hadoop fs -cat /dir/a.txt chmod hadoop fs -chmod 777 /dir/a.txt chown hadoop fs -chown hadoop:hadoop /dir/a.txt appendToFile hadoop fs -appendToFile a.txt /dir/b.txt setrep hadoop fs -setrep -w 2 /dir/a.txt Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 13:50:13 "},"docs/05.MapReduce计算模型/0.MapReducer计算模型介绍.html":{"url":"docs/05.MapReduce计算模型/0.MapReducer计算模型介绍.html","title":"MapReduce分布式计算","keywords":"","body":"1.理解MapReduce思想 分而治之 Map负责分 Reduce负责合， Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 20:19:37 "},"docs/daily/":{"url":"docs/daily/","title":"Daily Notes","keywords":"","body":"记录每日学习记录 Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 20:09:01 "},"docs/daily/day12.html":{"url":"docs/daily/day12.html","title":"Day 12","keywords":"","body":"今天一定要搞搞淘宝店。 搞钱才是王道！！！ 谢谢hdfs和map reduce的代码 切片不足的时候的策略 当切片的时候，当后面的加起来 分区 分区主要是为了减轻每个分区的数据压力。 避免数据倾斜。 用groupby.多个reduce, 数据分散开，更大。 combiner 在提交给reducer前，提前对数据局部聚合。提交执行效率。 减少IO和网络开销，提升性能。 combiner慎用！ 在hive中，其实只需要调一个参数。 分组 分组:将相同K2的v2放在集合中。 综合案例 用MapReduce做数据清洗。 后续基本都用HiveSQL, SparkSQL, 和FlinkSQL了 Copyright © Jian Tao 2020-2021 all right reserved，powered by GitbookLast time edited： 2021-10-30 20:34:38 "}}