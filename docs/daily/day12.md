今天一定要搞搞淘宝店。

搞钱才是王道！！！

谢谢hdfs和map reduce的代码


***
### 切片不足的时候的策略
当切片的时候，当后面的加起来 <=12.8MB的话，就不用。就把剩余的所有切片当做一个
整体。


### 分区

分区主要是为了减轻每个分区的数据压力。
避免数据倾斜。
用groupby.  
多个reduce, 数据分散开，更大。

### combiner 

在提交给reducer前，提前对数据局部聚合。提交执行效率。
减少IO和网络开销，提升性能。
combiner慎用！
在hive中，其实只需要调一个参数。


### 分组


### 综合案例

用MapReduce做数据清洗。 

后续基本都用`HiveSQL`, `SparkSQL`, 和`FlinkSQL`了









